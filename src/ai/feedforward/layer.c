#include "layer.h"

#include <stdio.h>
#include <stdint.h>
#include <stdbool.h>
#include <stdlib.h>
#include <assert.h>

// List of static functions used for squashing values
#include "activation.h"

/*******************************************
 *               Local types               *
 *******************************************/
typedef struct ffn_layer_s {
  // A bit mask of the allowed activation functions used for
  //  initialisation and mutations.
  uint32_t   allowedActivations;
  // Number of neurons in layer.
  uint64_t   numNeurons;
  // Number of connections each neuron has to previous layer.
  uint64_t   numConnections;
  ffn_neuron_t **neurons;
  // Values generated by the neurons.
  float     *values;
} ffn_layer_t;

/*******************************************
 *             Local functions             *
 *******************************************/

/*******************************************
 *           Exported functions            *
 *******************************************/
ffn_layer_t *ffnLayerCreate( uint64_t size, uint64_t inputs, uint64_t connections, uint32_t allowedActivations, bool initialise )
{
  uint64_t i, last;
  ffn_layer_t *layer;

  layer = malloc( sizeof(ffn_layer_t) );
  if( layer == NULL ) {
    goto layer_err_object;
  }

  layer->allowedActivations = allowedActivations;
  layer->numNeurons = size;
  layer->numConnections = connections;

  // Neurons
  layer->neurons = malloc( layer->numNeurons * sizeof(ffn_neuron_t*) );
  if( layer->neurons == NULL ) {
    goto layer_err_neurons;
  }

  // Create neurons here
  for( i = 0; i < layer->numNeurons; i++ ) {
    uint64_t tmpSeed;
    if( initialise && layer->numConnections != inputs ) {
      tmpSeed = ((uint64_t)rand() << 32) | (uint64_t)rand();
    } else {
      tmpSeed = 0;
    }

    layer->neurons[i] = ffnNeuronCreate( inputs, randomActivation( layer->allowedActivations ), 
					 layer->numConnections, tmpSeed, initialise );
    if( layer->neurons[i] == NULL ) {
      fprintf( stderr, "ffnLayerCreate() - Unable to create neuron %d\n", (int) i );
      last = i;
      goto layer_err_neurons_create;
    }
  }

  // Values
  layer->values = malloc( sizeof(float) * layer->numNeurons );
  if( layer->values == NULL ) {
    goto layer_err_values;
  }
  for( i = 0; i < layer->numNeurons; i++ ) {
    layer->values[i] = 0.0;
  }

  // Done
  return layer;


  // Error handling
 layer_err_values:
  last = layer->numNeurons;

 layer_err_neurons_create:
  for( i = 0; i < last; i++ ) {
    ffnNeuronDestroy( layer->neurons[i] );
  }
  free( layer->neurons );

 layer_err_neurons:
  free( layer );

 layer_err_object:
  return NULL;
}

void ffnLayerDestroy( ffn_layer_t *layer )
{
  assert( layer != NULL );

  uint64_t i;
  free( layer->values );
  for( i = 0; i < layer->numNeurons; i++ ) {
    ffnNeuronDestroy( layer->neurons[i] );
  }
  free( layer->neurons );
  free( layer );
}

void ffnLayerMutate( ffn_layer_t *layer, double mutateRate )
{
  assert( layer != NULL );

  uint64_t i;
  for( i = 0; i < layer->numNeurons; i++ ) {
    ffnNeuronMutate( layer->neurons[i], mutateRate, layer->allowedActivations );
  }
}

bool ffnLayerRun( ffn_layer_t *layer, float *inputs )
{
  assert( layer != NULL );
  assert( inputs != NULL );

  uint64_t neur;
  for( neur = 0; neur < layer->numNeurons; neur++ ) {
    layer->values[neur] = ffnNeuronRun( layer->neurons[neur], inputs );
  }

  return true;
}

uint64_t ffnLayerGetNumConnections( ffn_layer_t *layer )
{
  assert( layer != NULL );

  return layer->numConnections;
}

uint64_t ffnLayerGetNumNeurons( ffn_layer_t *layer )
{
  assert( layer != NULL );

  return layer->numNeurons;
}

uint32_t ffnLayerGetAllowedActivations( ffn_layer_t *layer )
{
  assert( layer != NULL );

  return layer->allowedActivations;
}

float *ffnLayerGetValues( ffn_layer_t *layer )
{
  assert( layer != NULL );

  return layer->values;
}

float ffnLayerGetValue( ffn_layer_t *layer, uint64_t neuron )
{
  assert( layer != NULL );
  assert( neuron < layer->numNeurons );

  return layer->values[neuron];
}

void ffnLayerSetNeuronSeed( ffn_layer_t *layer, uint64_t neuron, uint64_t seed )
{
  assert( layer != NULL );
  assert( neuron < layer->numNeurons );

  ffnNeuronSetSeed( layer->neurons[neuron], seed );
}

uint64_t ffnLayerGetNeuronSeed( ffn_layer_t *layer, uint64_t neuron )
{
  assert( layer != NULL );
  assert( neuron < layer->numNeurons );

  return ffnNeuronGetSeed( layer->neurons[neuron] );
}

void ffnLayerSetNeuronBias( ffn_layer_t *layer, uint64_t neuron, float bias )
{
  assert( layer != NULL );
  assert( neuron < layer->numNeurons );

  ffnNeuronSetBias( layer->neurons[neuron], bias );
}

float ffnLayerGetNeuronBias( ffn_layer_t *layer, uint64_t neuron )
{
  assert( layer != NULL );
  assert( neuron < layer->numNeurons );

  return ffnNeuronGetBias( layer->neurons[neuron] );
}

void ffnLayerSetNeuronWeight( ffn_layer_t *layer, uint64_t neuron, uint64_t source, float weight )
{
  assert( layer != NULL );
  assert( neuron < layer->numNeurons );

  ffnNeuronSetWeight( layer->neurons[neuron], source, weight );
}

float ffnLayerGetNeuronWeight( ffn_layer_t *layer, uint64_t neuron, uint64_t source )
{
  assert( layer != NULL );
  assert( neuron < layer->numNeurons );

  return ffnNeuronGetWeight( layer->neurons[neuron], source );
}

void ffnLayerSetNeuronActivation( ffn_layer_t *layer, uint64_t neuron, activation_type_t activation )
{
  assert( layer != NULL );
  assert( neuron < layer->numNeurons );

  ffnNeuronSetActivation( layer->neurons[neuron], activation );
}

activation_type_t ffnLayerGetNeuronActivation( ffn_layer_t *layer, uint64_t neuron )
{
  assert( layer != NULL );
  assert( neuron < layer->numNeurons );

  return ffnNeuronGetActivation( layer->neurons[neuron] );
}

uint64_t ffnLayerGetNeuronConnection( ffn_layer_t *layer, uint64_t neuron, uint64_t index )
{
  assert( layer != NULL );
  assert( neuron < layer->numNeurons );
  assert( index < layer->numConnections );

  return ffnNeuronGetConnection( layer->neurons[neuron], index );
}
